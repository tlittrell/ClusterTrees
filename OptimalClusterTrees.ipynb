{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster trees function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using JuMP, Gurobi, GLM, DataFrames, Plots, Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mFailed to import required Python module sklearn.\n\nFor automated sklearn installation, try configuring PyCall to use the Conda.jl package's Python \"Miniconda\" distribution within Julia. Relaunch Julia and run:\n    ENV[\"PYTHON\"]=\"\"\n    Pkg.build(\"PyCall\")\nbefore trying again.\n\nThe pyimport exception was: PyError (ccall(@pysym(:PyImport_ImportModule), PyPtr, (Cstring,), name)\n\nThe Python package sklearn could not be found by pyimport. Usually this means\nthat you did not install sklearn in the Python version being used by PyCall.\n\nPyCall is currently configured to use the Python version at:\n\n/usr/bin/python\n\nand you should use whatever mechanism you usually use (apt-get, pip, conda,\netcetera) to install the Python package containing the sklearn module.\n\nOne alternative is to re-configure PyCall to use a different Python\nversion on your system: set ENV[\"PYTHON\"] to the path/name of the python\nexecutable you want to use, run Pkg.build(\"PyCall\"), and re-launch Julia.\n\nAnother alternative is to configure PyCall to use a Julia-specific Python\ndistribution via the Conda.jl package (which installs a private Anaconda\nPython distribution), which has the advantage that packages can be installed\nand kept up-to-date via Julia.  As explained in the PyCall documentation,\nset ENV[\"PYTHON\"]=\"\", run Pkg.build(\"PyCall\"), and re-launch Julia. Then,\nTo install the sklearn module, you can use `pyimport_conda(\"sklearn\", PKG)`,\nwhere PKG is the Anaconda package the contains the module sklearn,\nor alternatively you can use the Conda package directly (via\n`using Conda` followed by `Conda.add` etcetera).\n\n) <type 'exceptions.ImportError'>\nImportError('No module named sklearn',)\n\n\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mFailed to import required Python module sklearn.\n\nFor automated sklearn installation, try configuring PyCall to use the Conda.jl package's Python \"Miniconda\" distribution within Julia. Relaunch Julia and run:\n    ENV[\"PYTHON\"]=\"\"\n    Pkg.build(\"PyCall\")\nbefore trying again.\n\nThe pyimport exception was: PyError (ccall(@pysym(:PyImport_ImportModule), PyPtr, (Cstring,), name)\n\nThe Python package sklearn could not be found by pyimport. Usually this means\nthat you did not install sklearn in the Python version being used by PyCall.\n\nPyCall is currently configured to use the Python version at:\n\n/usr/bin/python\n\nand you should use whatever mechanism you usually use (apt-get, pip, conda,\netcetera) to install the Python package containing the sklearn module.\n\nOne alternative is to re-configure PyCall to use a different Python\nversion on your system: set ENV[\"PYTHON\"] to the path/name of the python\nexecutable you want to use, run Pkg.build(\"PyCall\"), and re-launch Julia.\n\nAnother alternative is to configure PyCall to use a Julia-specific Python\ndistribution via the Conda.jl package (which installs a private Anaconda\nPython distribution), which has the advantage that packages can be installed\nand kept up-to-date via Julia.  As explained in the PyCall documentation,\nset ENV[\"PYTHON\"]=\"\", run Pkg.build(\"PyCall\"), and re-launch Julia. Then,\nTo install the sklearn module, you can use `pyimport_conda(\"sklearn\", PKG)`,\nwhere PKG is the Anaconda package the contains the module sklearn,\nor alternatively you can use the Conda package directly (via\n`using Conda` followed by `Conda.add` etcetera).\n\n) <type 'exceptions.ImportError'>\nImportError('No module named sklearn',)\n\n\u001b[39m",
      "",
      "Stacktrace:",
      " [1] \u001b[1mpyimport_conda\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Applications/JuliaPro-0.6.2.2.app/Contents/Resources/pkgs-0.6.2.2/v0.6/PyCall/src/PyCall.jl:609\u001b[22m\u001b[22m",
      " [2] \u001b[1mimport_sklearn\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Applications/JuliaPro-0.6.2.2.app/Contents/Resources/pkgs-0.6.2.2/v0.6/ScikitLearn/src/Skcore.jl:114\u001b[22m\u001b[22m",
      " [3] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:522\u001b[22m\u001b[22m"
     ]
    }
   ],
   "source": [
    "using ScikitLearn, StatsBase\n",
    "# Load in the DecisionTreeClassifier method from ScikitLearn\n",
    "@sk_import tree: DecisionTreeClassifier;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions for optimal cluster trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_parent_nodes (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_parent_nodes(num_nodes)\n",
    "    \n",
    "    # Compute the parent nodes and paths through the tree for all nodes.\n",
    "    # Nodes are numbered 1:N starting top to bottom and left to right\n",
    "    # e.g.\n",
    "    #     1\n",
    "    #  2    3\n",
    "    # 4 5  6 7\n",
    "    \n",
    "    if num_nodes < 1\n",
    "        throw(ArgumentError(\"Number of nodes must be greater than 1\"))\n",
    "    end\n",
    "    \n",
    "    direct_parent = Dict()\n",
    "    direct_parent[1] = []\n",
    "    left_parents = Dict()\n",
    "    left_parents[1] = []\n",
    "    right_parents = Dict()\n",
    "    right_parents[1] = []\n",
    "\n",
    "\n",
    "    for node in 2:num_nodes\n",
    "        par = Int(floor(node/2))\n",
    "        direct_parent[node] = par\n",
    "        if (par == node/2)\n",
    "            left_parents[node] = push!(copy(left_parents[par]), par)\n",
    "            right_parents[node] = right_parents[par]\n",
    "        else\n",
    "            right_parents[node] = push!(copy(right_parents[par]), par)\n",
    "            left_parents[node] = left_parents[par]\n",
    "        end\n",
    "    end\n",
    "    return direct_parent, left_parents, right_parents\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_child_nodes (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_child_nodes(num_nodes)\n",
    "    \n",
    "    # Compute the child nodes and paths through the tree for all nodes.\n",
    "    # Nodes are numbered 1:N starting top to bottom and left to right\n",
    "    # e.g.\n",
    "    #     1\n",
    "    #  2    3\n",
    "    # 4 5  6 7\n",
    "    \n",
    "    if num_nodes < 1\n",
    "        throw(ArgumentError(\"Number of nodes must be greater than 1\"))\n",
    "    end\n",
    "    \n",
    "    all_children = Dict()\n",
    "    left_children = Dict()\n",
    "    right_children = Dict()\n",
    "    \n",
    "    Leaves = Int(2^floor(log(2,num_nodes))):num_nodes\n",
    "    for leaf in Leaves\n",
    "        all_children[leaf] = []\n",
    "        left_children[leaf] = []\n",
    "        right_children[leaf] = []   \n",
    "    end\n",
    "\n",
    "    for node in num_nodes:-1:2\n",
    "        par = Int(floor(node/2))\n",
    "\n",
    "        if !haskey(all_children,par) all_children[par] = [] end\n",
    "        if !haskey(left_children,par) left_children[par] = [] end\n",
    "        if !haskey(right_children,par) right_children[par] = [] end\n",
    "\n",
    "        all_children[par] = vcat(push!(copy(all_children[par]),node), all_children[node])\n",
    "\n",
    "        if (par == node/2) # current node is left child of parent\n",
    "            left_children[par] = vcat(push!(copy(left_children[par]),node), all_children[node])\n",
    "        else            # current node is right child of parent\n",
    "            right_children[par] = vcat(push!(copy(right_children[par]),node), all_children[node])\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return all_children, left_children, right_children\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_branch_leaf_sets (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tree_nodes(depth) = 2^(depth+1)-1\n",
    "\n",
    "function get_branch_leaf_sets(num_nodes,max_depth)\n",
    "    # Return the node numbers for the interior and leaf nodes\n",
    "    Branches = 1:2^(max_depth)-1\n",
    "    Leaves = 2^(max_depth):num_nodes\n",
    "    return Branches, Leaves\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calculate_epsilon (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function calculate_epsilon(X,p)\n",
    "    # Calculate the epsilon used to make the splitting constraints\n",
    "    # valid (otherwise we get < constraints)\n",
    "    ϵ = zeros(p)\n",
    "    for j = 1:p\n",
    "        sXj = sort(X[:,j])\n",
    "        diffs = sXj[2:end]-sXj[1:end-1]\n",
    "        ϵ[j] = minimum(diffs[:,diffs != 0])\n",
    "    end\n",
    "    \n",
    "    ϵ_mx = maximum(ϵ)\n",
    "    return ϵ, ϵ_mx\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "check_local_sparsity (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function check_local_sparsity(local_sparsity,p)\n",
    "    if (local_sparsity != Int(local_sparsity)) & (local_sparsity != :all)\n",
    "        throw(ArgumentError(\"Local sparsity must be set to an integer or ':all'.\"))\n",
    "    elseif (local_sparsity < 1)\n",
    "        throw(ArgumentError(\"Local sparsity must be greater than 1\"))\n",
    "    elseif (local_sparsity > p)\n",
    "        throw(ArgumentError(\"Local sparsity must be less than the number of features\"))\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "check_margin_parameter (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function check_margin_parameter(maximize_margin)\n",
    "    if (maximize_margin != true) & (maximize_margin != false)\n",
    "        throw(ArgumentError(\"Maximum margin parameter must be a boolean.\")) \n",
    "    end\n",
    "    if maximize_margin m_p = 1 else m_p = 0 end\n",
    "    return m_p\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss_normalization_factor (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_normalization_factor(X) = sum(abs.(X .- mean(X,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f_start (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function f_start(kmeans)\n",
    "    clustering = assignments(kmeans)\n",
    "    result = kmeans_clusters.centers'[clustering,:]\n",
    "    return result\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "km_pp_centers (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function km_pp_centers(Xnor, K)\n",
    "    obs = size(Xnor,1)\n",
    "    cent_idxs = [rand(1:obs)]\n",
    "    for ii = 1:(K-1)\n",
    "        Lk = length(cent_idxs)\n",
    "        d_mat = zeros(obs,Lk)\n",
    "        for jj in 1:Lk\n",
    "            d_mat[:,jj] = sum(abs.(Xnor .- Xnor[cent_idxs[jj],:]'),2)\n",
    "        end\n",
    "\n",
    "        min_ds2 = minimum(d_mat,2)  \n",
    "        new_k = StatsBase.sample(1:obs, Weights(min_ds2[:]))\n",
    "        append!(cent_idxs,new_k)\n",
    "    end\n",
    "\n",
    "    return Xnor[cent_idxs,:];\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "warmstart (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function warmstart(Xnor,K,N_min,max_depth, warm_start) \n",
    "    n, p = size(Xnor)\n",
    "    if warm_start\n",
    "        cent_i = km_pp_centers(Xnor, K)\n",
    "        kmeans_clusters = kmeans!(Xnor',cent_i')\n",
    "\n",
    "        labels = assignments(kmeans_clusters)\n",
    "\n",
    "        tree = DecisionTreeClassifier(min_samples_leaf=N_min, max_depth=max_depth, \n",
    "            random_state=1234, min_impurity_decrease = 0.25,\n",
    "            criterion=\"entropy\")\n",
    "        ScikitLearn.fit!(tree, Xnor, labels)\n",
    "\n",
    "        new_labels = ScikitLearn.predict(tree,Xnor)\n",
    "\n",
    "        μ_st = zeros(K,p)\n",
    "\n",
    "        for ii in unique(new_labels)\n",
    "            μ_st[ii,:] = mean(Xnor[(new_labels .== ii),:],1)\n",
    "        end\n",
    "\n",
    "        f_st = μ_st[new_labels,:]\n",
    "\n",
    "        num_nodes = num_tree_nodes(max_depth)\n",
    "        Branches, Leaves = get_branch_leaf_sets(num_nodes,max_depth)\n",
    "        all_children, left_children, right_children = get_child_nodes(num_nodes);\n",
    "\n",
    "        tr_features = tree[:tree_][:feature]'\n",
    "        tr_bs = tree[:tree_][:threshold]'\n",
    "        tr_lc = tree[:tree_][:children_left]'\n",
    "        tr_rc =  tree[:tree_][:children_right]'\n",
    "\n",
    "        lB = length(Branches)\n",
    "        a_st = zeros(lB,p)\n",
    "        b_st = zeros(lB,1)\n",
    "\n",
    "        BranchPair = zeros(Int, num_nodes)\n",
    "        BranchPair[1] = 1\n",
    "        for m in Branches\n",
    "            idx = BranchPair[m]\n",
    "            feat_idx = tr_features[idx]+1\n",
    "            if feat_idx > -1\n",
    "                a_st[m,feat_idx] = 1\n",
    "                b_st[m] = tr_bs[idx]\n",
    "            end\n",
    "            BranchPair[left_children[m][1]] = tr_lc[idx]+1\n",
    "            BranchPair[right_children[m][1]] = tr_rc[idx]+1\n",
    "        end\n",
    "\n",
    "        ah_st = abs.(a_st)\n",
    "        \n",
    "        d_st = 1*(sum(a_st,2) .== 1)\n",
    "    else\n",
    "        num_nodes = num_tree_nodes(max_depth)\n",
    "        Branches, Leaves = get_branch_leaf_sets(num_nodes,max_depth)\n",
    "        lB = length(Branches)\n",
    "        \n",
    "        μ_st = NaN*ones(K,p)\n",
    "        f_st = NaN*ones(n,p)\n",
    "        a_st = NaN*ones(lB,p)\n",
    "        b_st = NaN*ones(lB,1)\n",
    "        ah_st = NaN*ones(lB,p)\n",
    "        d_st = NaN*ones(lB,1)\n",
    "    end\n",
    "    \n",
    "    return Dict(\"μ_st\" => μ_st, \"f_st\" => f_st,\n",
    "            \"a_st\" => a_st, \"b_st\" => b_st,\n",
    "            \"ah_st\" => ah_st, \"d_st\" => d_st)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model\n",
    "\n",
    "#### Parameters and pre-computed values\n",
    "Our formulation uses the following parameters, which are input into the function or pre-computed:\n",
    "* $N$ the number of nodes, which is determined by the depth of a tree\n",
    "* $P_t^L$ the set of left parents for leaf $t$. Only defined for the leaves.\n",
    "* $P_t^R$ the set of right parents for leaf $t$. Only defined for the leaves.\n",
    "* $P_m^d$ the single direct parent node for a given node $m$. Defined for every node except the root for which it is null.\n",
    "* $C_m^L$ the set of all left child nodes for a given node $m$. In the code we only ever care about the intersection of this with the set of leaf nodes.\n",
    "* $C_m^R$ the set of all right child nodes for a given node $m$. In the code we only ever care about the intersection of this with the set of leaf nodes.\n",
    "* $B$ the set of branch (interior i.e. not leaf) nodes\n",
    "* $L$ the set of leaf nodes\n",
    "* $X \\in \\mathbb{R}^{n \\times p}$ the data\n",
    "* $l_s \\in \\{1,...,p\\}$ the local sparsity parameter used to generate constraints\n",
    "* $m_p \\in \\{0,1\\}$ the Boolean specifying whether the formulation should consider margin\n",
    "* $c_p$ the complexity parameter\n",
    "* $K$ the number of clusters\n",
    "* $\\Omega$ the loss normalization factor defined as the loss from assigning all points to one cluster.\n",
    "\n",
    "#### Model variables\n",
    "* $a_{j,m}$ for $j \\in \\{1,...,p\\}$ and $m \\in B$ is the hyperplane coefficient for the $j$th variable at branch $m$\n",
    "* $\\hat{a}_{j,m}$ for $j \\in \\{1,...,p\\}$ and $m \\in B$ is the absolute value of $a$\n",
    "* $b_m$ for $m \\in B$ is the offset for the hyperplane at that split\n",
    "* $z_{i,t} \\in \\{0,1\\}$ denotes whether point $i$ is assigned to leaf $t$\n",
    "* $\\delta_{i,m}$ is the relative distance of observation $i$ from hyperplane $m$ \n",
    "* $\\eta_m \\leq 2$ is the margin for plane $m$. The constraint comes from normalizing the data.\n",
    "* $d_m \\in \\{0,1\\}$ determines whether hyperplane $m$ is included in the tree \n",
    "* $s_{j,m} \\in \\{0,1\\}$ for $j \\in \\{1,...,p\\}$ and $m \\in B$ determines whether feature $j$ is included in hyperplane $m$\n",
    "* $\\mu_{k,j}$ is the L1-centroid of the $j$th feature in cluster $k$\n",
    "* $\\beta_{t,j}$ for $t \\in L$ and $j \\in \\{1,...,p\\}$ is the model's predicted value for the $j$th feature which is constrained to be a centroid\n",
    "* $w_{k,t} \\in \\{0,1\\}$ for $k \\in \\{1,...,K\\}$ and $t \\in L$ determines whether leaf $t$ is assigned to cluster $k$\n",
    "* $f_{i,j}$ is the predicted value in the $j$th feature for point $i$ and is used to link the predicted values and centroids\n",
    "* $\\alpha_{t,j,k} \\geq 0$ for $t \\in L$, $j \\in \\{1,...,p\\}$, and $k \\in \\{1,...,K\\}$ is an auxiliary variable used to linearize $\\mu_{k,j} w_{k,t}$\n",
    "* $\\gamma_{t,j,i} \\geq 0$ for $t \\in L$, $j \\in \\{1,...,p\\}$, and point $i$ is an auxiliary variable used to linearize $\\beta_{t,j}z_{i,t}$\n",
    "* $\\psi_{i,j} \\geq 0$ is the loss in the $j$th feature for the $i$th point\n",
    "\n",
    "#### Constraints\n",
    "The following constraints are used to define the margin. The second and third constraint say that the margin is not affected by points that don't lie in a relevant leaf. In theory we would use the absolute value of distance in the second and third constraint but, because this has no upper bound and defines margin, which is substracted in the objective function, it leads to garbage solutions. Instead we use the knowledge that $\\delta_{i,m}$ is negative for all left children and positive for all right children. These rely on the upper bound on margin that was defined above.\n",
    "* $\\sum_{j=1}^p(a_{j,m}X_{i,j}) - b_m = \\delta_{i,m} \\qquad \\forall i=1,..,n; m \\in B$ defines the relative distance to the plane i.e. defines $\\delta_{i,m}$\n",
    "* $\\eta_m \\leq -\\delta_{i,m} + 2(1-z_{i,t}) \\qquad \\forall i;m,t \\in C_m^L$\n",
    "* $\\eta_m \\leq \\delta_{i,m} + 2(1-z_{i,t}) \\qquad \\forall i;m,t \\in C_m^R$\n",
    "\n",
    "The following constraints enforce all the hyperplane splits for each point in each leaf. \n",
    "* $-1 \\leq a_{j,m} \\leq 1$ for all $j;m \\in B$\n",
    "* $\\hat{a}_{j,m} \\geq a_{j,m}$ and $\\hat{a}_{j,m} \\geq - a_{j,m}$ for all $j;m$ defines the absolute value\n",
    "* $\\sum_{j=1}^p(a_{j,m}X_{i,j}) - b_m + \\epsilon \\leq (2+\\epsilon)(1-z_{i,t})$ for all $i;t \\in B;m \\in P_t^L$. This enforces the left branch splits.\n",
    "* $\\sum_{j=1}^p(a_{j,m}X_{i,j}) - b_m \\geq -2(1-z_{i,t})$ for all $i;t \\in B;m \\in P_t^R$. This enforces the right branch splits. \n",
    "\n",
    "Make sure each point is assigned to one leaf\n",
    "* $\\sum_{t \\in L} z_{i,j} = 1 \\forall i$\n",
    "\n",
    "Complexity constraints control the coefficients that can be used in a given hyperplan\n",
    "* $\\sum_{j=1}^p \\leq l_s \\forall m$ ensures that we don't use more features than allowed by the local sparsity parameter at each split $m$\n",
    "* $\\sum_{j=1}^p \\hat{a}_{j,m} \\leq d_m \\forall m$ forces all coefficents to 0 if the split isn't used\n",
    "* $-d_m \\leq b_m \\leq d_m \\forall m$ forces the offset to be 0 if a split isn't used\n",
    "* $-s_{j,m} \\leq a_{j,m} \\leq s_{j,m}$ for all $j,m$ forces $a$ to be 0 if the $j$th variable isn't used\n",
    "* $s_{j,m} \\leq d_m$ for all $j,m$ forces consistency between $d$ and $s$\n",
    "* $d_m \\leq d_{P_m^d}$ for all $m \\in B \\setminus \\{1\\}$ ensures that, if a split higher up in the tree is turned off, all splits below that are turned off\n",
    "\n",
    "Cluster constraints.  N.B. THIS CONSTRAINT IS WRONG\n",
    "* $\\beta_{t,j} \\leq d_{P_t^d}$ for all $t \\in L, j$\n",
    "\n",
    "Make sure that the prediction in each leaf is equal to the centroid of exactly one cluster\n",
    "* $\\alpha_{t,j,k} \\leq w_{k,t}$ for all $t \\in L, j \\in \\{1,...,p\\}, k \\in \\{1,..,K\\}$\n",
    "* $\\alpha_{t,j,k} \\leq \\mu_{k,j}$ for all $t \\in L, j \\in \\{1,...,p\\}, k \\in \\{1,..,K\\}$\n",
    "* $\\alpha_{t,j,k} \\geq \\mu_{k,j} - (1-w_{k,t})$ for all $t \\in L, j \\in \\{1,...,p\\}, k \\in \\{1,..,K\\}$\n",
    "* $\\sum_{k=1}^K w_{k,t} = 1$ for all $t \\in L$ ensures each leaf is assigned to one cluster\n",
    "* $\\beta_{j,t} = \\sum_{k=1}^K \\alpha_{t,j,k}$\n",
    "\n",
    "Connect the predictions to each point.\n",
    "* $f_{i,j} = \\sum_{t \\in L} \\gamma_{t,i,j}$ for all $i,j$\n",
    "* $\\gamma_{t,i,j} \\leq z_{i,t}$ for all $t \\in L,i,j$\n",
    "* $\\gamma_{t,i,j} \\leq \\beta_{t,j}$ for all $t \\in L,i,j$\n",
    "* $ \\gamma_{t,i,j} \\geq \\beta_{t,j} - (1-z_{i,t})$ for all $t \\in L,i,j$\n",
    "\n",
    "Define the loss as the L1 distance from a point to its assigned centroid\n",
    "* $\\psi_{i,j} \\geq f_{i,j} - X_{i,j}$ for all $i,j$\n",
    "* $\\psi_{i,j} \\geq -f_{i,j} + X_{i,j}$ for all $i,j$\n",
    "\n",
    "#### Objective function\n",
    "The objective function includes loss from distance to the centroid, complexity, and margin:\n",
    "$$ \\min \\frac{1}{\\Omega} \\sum_{i,j} \\psi_{i,j} + c_p \\sum_{j,m} s_{j,m} - \\frac{m_p}{\\Omega^2} \\sum_{m} \\eta_m $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClusterTree (generic function with 1 method)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function ClusterTree(X,c_p,max_depth,K;local_sparsity=1,maximize_margin=true, warm_start = false, N_min = 2)\n",
    "    # Pre-compute various model factors\n",
    "    num_nodes = num_tree_nodes(max_depth)\n",
    "    Branches, Leaves = get_branch_leaf_sets(num_nodes,max_depth)\n",
    "    direct_parent, left_parents, right_parents = get_parent_nodes(num_nodes)\n",
    "    all_children, left_children, right_children = get_child_nodes(num_nodes)\n",
    "    n,p = size(X)\n",
    "    if (local_sparsity == :all) local_sparsity = p end\n",
    "    m_p = check_margin_parameter(maximize_margin)\n",
    "    check_local_sparsity(local_sparsity,p)\n",
    "    Ω = loss_normalization_factor(X)\n",
    "    \n",
    "\n",
    "    starts = warmstart(X,K,N_min,max_depth,warm_start)\n",
    "    \n",
    "    mod = Model(solver = GurobiSolver(OutputFlag=0))\n",
    "    # Split Variables\n",
    "    if (local_sparsity == 1) \n",
    "        @variable(mod, a[j=1:p,t in Branches], Bin, start = starts[\"a_st\"][t,j])\n",
    "        @variable(mod, b[t in Branches] >= 0, start = starts[\"b_st\"][t])\n",
    "    else\n",
    "        @variable(mod, a[j=1:p,t in Branches], start = starts[\"a_st\"][t,j])\n",
    "        @variable(mod, a_hat[j=1:p,t in Branches], start = starts[\"ah_st\"][t,j]) \n",
    "        @variable(mod, b[t in Branches], start = starts[\"b_st\"][t])\n",
    "    end\n",
    "    @variable(mod, z[i=1:n,t in Leaves], Bin)\n",
    "    \n",
    "    # MinBucket Variables\n",
    "    @variable(mod, l[t in Leaves], Bin)\n",
    "    \n",
    "    # MinBucket Constraints\n",
    "    @constraint(mod, MinB1[t in Leaves, i=1:n], z[i,t] <= l[t])\n",
    "    @constraint(mod, MinB2[t in Leaves], sum(z[i,t] for i = 1:n) >= N_min*l[t])\n",
    "    \n",
    "    # Hyperplane Distance / Margin Variables\n",
    "    @variable(mod, margin[m in Branches] >= 0)\n",
    "    \n",
    "    if (local_sparsity != 1)\n",
    "        @constraint(mod, [m in Branches], margin[m] <= 2)                           \n",
    "        for m in Branches                                                           \n",
    "            @constraint(mod, [i=1:n, leaf in intersect(Leaves,left_children[m])], \n",
    "                margin[m] <= -(sum(a[j,m]*X[i,j] for j = 1:p) - b[m]) + 2*(1-z[i,leaf]))\n",
    "            @constraint(mod, [i=1:n, leaf in intersect(Leaves,right_children[m])], \n",
    "                margin[m] <= (sum(a[j,m]*X[i,j] for j = 1:p) - b[m]) + 2*(1-z[i,leaf])) \n",
    "        end\n",
    "    else\n",
    "        @constraint(mod, [m in Branches], margin[m] <= 1)  \n",
    "        for m in Branches                                                           \n",
    "            @constraint(mod, [i=1:n, leaf in intersect(Leaves,left_children[m])], \n",
    "                margin[m] <= -(sum(a[j,m]*X[i,j] for j = 1:p) - b[m]) + (1-z[i,leaf]))\n",
    "            @constraint(mod, [i=1:n, leaf in intersect(Leaves,right_children[m])], \n",
    "                margin[m] <= (sum(a[j,m]*X[i,j] for j = 1:p) - b[m]) + (1-z[i,leaf])) \n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Split constraints enforce all parent splits for a leaf for each point in that leaf\n",
    "    if (local_sparsity == 1)\n",
    "        ϵ, ϵ_max = calculate_epsilon(X,p)\n",
    "        for leaf in Leaves\n",
    "            @constraint(mod, [i=1:n,m in left_parents[leaf]], \n",
    "                sum(a[j,m]*(X[i,j]+ϵ[j]) for j = 1:p) - b[m] <=  (1+ϵ_max)*(1-z[i,leaf]))\n",
    "            @constraint(mod, [i=1:n,m in right_parents[leaf]], \n",
    "                sum(a[j,m]*X[i,j] for j = 1:p) - b[m] >= - (1-z[i,leaf])) \n",
    "        end\n",
    "    else\n",
    "        ϵ = 0.005\n",
    "        @constraint(mod, [j=1:p,t in Branches], a[j,t] >= -1)\n",
    "        @constraint(mod, [j=1:p,t in Branches], a[j,t] <= 1)\n",
    "        @constraint(mod, [j=1:p,t in Branches], a_hat[j,t] >= a[j,t])\n",
    "        @constraint(mod, [j=1:p,t in Branches], a_hat[j,t] >= -a[j,t])\n",
    "        for leaf in Leaves\n",
    "            @constraint(mod, [i=1:n,m in left_parents[leaf]], \n",
    "                sum(a[j,m]*X[i,j] for j = 1:p) - b[m] + ϵ <= (2+ϵ)*(1-z[i,leaf]))\n",
    "            @constraint(mod, [i=1:n,m in right_parents[leaf]], \n",
    "                sum(a[j,m]*X[i,j] for j = 1:p) - b[m] >= - 2*(1-z[i,leaf])) \n",
    "        end\n",
    "    end\n",
    "    \n",
    "    @constraint(mod, each_point_one_leaf[i=1:n], \n",
    "        sum(z[i,t] for t in Leaves) == 1)\n",
    "    \n",
    "    # Complexity Variables\n",
    "    @variable(mod, d[t in Branches], Bin, start = starts[\"d_st\"][t])\n",
    "    if (local_sparsity != 1) \n",
    "        @variable(mod, s[j=1:p,t in Branches], Bin) \n",
    "    end\n",
    "    \n",
    "    # Complexity constraints\n",
    "    if (local_sparsity != 1)\n",
    "        @constraint(mod, NumSplits[t in Branches], sum(s[j,t] for j = 1:p) <= local_sparsity)\n",
    "        @constraint(mod, NumSplits2[t in Branches], sum(s[j,t] for j = 1:p) >= d[t])\n",
    "        @constraint(mod, MakeSplit1[t in Branches], sum(a_hat[j,t] for j=1:p) <= d[t])\n",
    "        @constraint(mod, MakeSplit2[t in Branches], b[t] <= d[t])\n",
    "        @constraint(mod, MakeSplit3[t in Branches], b[t] >= -d[t])\n",
    "        @constraint(mod, [j=1:p,t in Branches], a[j,t] <= s[j,t])\n",
    "        @constraint(mod, [j=1:p,t in Branches], a[j,t] >= -s[j,t])\n",
    "        @constraint(mod, [j=1:p,t in Branches], s[j,t] <= d[t])\n",
    "    else\n",
    "        @constraint(mod, MakeSplit1[t in Branches], sum(a[j,t] for j=1:p) == d[t])\n",
    "        @constraint(mod, MakeSplit2[t in Branches], b[t] <= d[t])\n",
    "    end\n",
    "    \n",
    "    @constraint(mod, [t in setdiff(Branches,1)], d[t] <= d[direct_parent[t]])\n",
    "    \n",
    "    # Cluster Variables\n",
    "    @variable(mod, μ[k = 1:K, j=1:p] >= 0,start = starts[\"μ_st\"][k,j])\n",
    "    @variable(mod, f[i = 1:n, j = 1:p] >= 0, start = starts[\"f_st\"][i,j])\n",
    "    @variable(mod, β[t in Leaves, j=1:p] >= 0)\n",
    "    @variable(mod, α[t in Leaves, j=1:p, k = 1:K] >= 0)\n",
    "    @variable(mod, γ[t in Leaves, j=1:p, i = 1:n] >= 0)\n",
    "\n",
    "    @constraint(mod, [k = 1:K, j=1:p],  μ[k,j] <= 1)\n",
    "    @constraint(mod, [i=1:n, j=1:p],  f[i,j] <= 1)\n",
    "    @constraint(mod, [t in Leaves, j=1:p], β[t,j] <= l[t])\n",
    "    @constraint(mod, [t in Leaves, j=1:p, k = 1:K], α[t,j,k] <= l[t])\n",
    "    @constraint(mod, [t in Leaves, j=1:p, i = 1:n], γ[t,j,i] <= l[t])    \n",
    "    \n",
    "    @variable(mod, w[k = 1:K, t in Leaves], Bin)\n",
    "\n",
    "    # Cluster Constraints\n",
    "    for m in Branches\n",
    "        @constraint(mod, [j=1:p, t in intersect(Leaves,left_children[m])], β[t,j] <= d[m])\n",
    "        @constraint(mod, [j=1:p, t in intersect(Leaves,left_children[m]), k = 1:K], α[t,j,k] <= d[m])\n",
    "        @constraint(mod, [j=1:p, t in intersect(Leaves,left_children[m]), i = 1:n], γ[t,j,i] <= d[m])\n",
    "        @constraint(mod, [t in intersect(Leaves,left_children[m])], l[t] <= d[m])\n",
    "    end\n",
    "\n",
    "    @constraint(mod, LinearizeMean1[t in Leaves, j=1:p, k = 1:K], α[t,j,k] <= w[k,t])\n",
    "    @constraint(mod, LinearizeMean2[t in Leaves, j=1:p, k = 1:K], α[t,j,k] <= μ[k,j])\n",
    "    @constraint(mod, LinearizeMean3[t in Leaves, j=1:p, k = 1:K], α[t,j,k] >= μ[k,j]-(1-w[k,t]))\n",
    "    @constraint(mod, Mean[t in Leaves, j=1:p], sum(α[t,j,k] for k = 1:K) == β[t,j])\n",
    "    \n",
    "    @constraint(mod, wConst[t in Leaves], sum(w[k,t] for k = 1:K) == l[t])\n",
    "    \n",
    "    @constraint(mod, LinearizePred1[t in Leaves, j=1:p, i = 1:n], γ[t,j,i] <= z[i,t])\n",
    "    @constraint(mod, LinearizePred2[t in Leaves, j=1:p, i = 1:n], γ[t,j,i] <= β[t,j])\n",
    "    @constraint(mod, LinearizePred3[t in Leaves, j=1:p, i = 1:n], γ[t,j,i] >= β[t,j]-(1-z[i,t]))\n",
    "    @constraint(mod, Pred[i = 1:n, j=1:p], sum(γ[t,j,i] for t in Leaves) == f[i,j])\n",
    "    \n",
    "    # Loss Variables\n",
    "    @variable(mod, L[i = 1:n, j = 1:p] >= 0)\n",
    "    \n",
    "    # Loss Constraints\n",
    "    @constraint(mod, Loss1[i = 1:n, j = 1:p], L[i,j] >= f[i,j]-X[i,j])   \n",
    "    @constraint(mod, Loss2[i=1:n, j=1:p], L[i,j] >= -f[i,j]+X[i,j])   \n",
    "    \n",
    "    if (local_sparsity == 1)\n",
    "        @objective(mod, Min, \n",
    "            (1/Ω)*sum(L[i,j] for i=1:n, j=1:p) + \n",
    "            c_p*sum(d[t] for t in Branches) -\n",
    "            m_p*(1/100)*(1/Ω)*sum(margin[m] for m in Branches))\n",
    "    else\n",
    "        @objective(mod, Min, \n",
    "            (1/Ω)*sum(L[i,j] for i=1:n, j=1:p) + \n",
    "            c_p*sum(s[j,t] for j=1:p, t in Branches) -\n",
    "            m_p*(1/100)*(1/Ω)*sum(margin[m] for m in Branches))\n",
    "    end\n",
    "\n",
    "    status = solve(mod)\n",
    "    println(\"Status = \", status)\n",
    "    return Dict(\"z\" => getvalue(z), \"μ\" => getvalue(μ),\n",
    "                \"a\" => getvalue(a), \"b\" => getvalue(b),\n",
    "                \"d\" => getvalue(d), \"w\" => getvalue(w),\n",
    "                \"l\" => getvalue(l), \"β\" => getvalue(β),\n",
    "                \"branches\" => Branches, \"leaves\" => Leaves,\n",
    "                \"direct parent\" => direct_parent,\n",
    "                \"left parents\" => left_parents,\n",
    "                \"right parents\" => right_parents,\n",
    "                \"obj\" => getobjectivevalue(mod))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate test data and visualize clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "plot_cluster_tree (generic function with 1 method)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function create_synthetic_data(n,μ,σ;seed = 1234)\n",
    "    srand(seed)\n",
    "    X = (μ[1].+σ[1]*randn(n[1],2)')'\n",
    "    for i = 2:size(n)[1]\n",
    "        new_x = (μ[i].+σ[i]*randn(n[i],2)')'\n",
    "        X = vcat(X,new_x)\n",
    "    end\n",
    "    return X\n",
    "end\n",
    "\n",
    "function synthetic_data_cluster_assignments(n)\n",
    "    Y = ones(Int, n[1],1)\n",
    "    for i = 2:size(n)[1]\n",
    "        y = i*ones(Int,n[i],1)\n",
    "        Y = vcat(Y,y)\n",
    "    end\n",
    "    return Y\n",
    "end\n",
    "\n",
    "function feature_scaling(X)\n",
    "    mx_X = maximum(X,1)\n",
    "    mn_X = minimum(X,1)\n",
    "    return (X .- mx_X)./(mn_X .- mx_X)\n",
    "end    \n",
    "\n",
    "function get_cluster_assignments(result)\n",
    "    obs, leaves = size(result[\"z\"][:,:])\n",
    "    which_t = [find(result[\"z\"][i,:])[1] for i = 1:obs]\n",
    "    t_to_k = zeros(Int, leaves)\n",
    "    for ii in sort(unique(which_t))\n",
    "        t_to_k[ii] = find(result[\"w\"][:,:][:,ii])[1]\n",
    "    end\n",
    "    return t_to_k[which_t]\n",
    "end\n",
    "\n",
    "function plot_cluster_tree(result,depth)\n",
    "    num_nodes = num_tree_nodes(max_depth)\n",
    "#     Branches, Leaves = get_branch_leaf_sets(num_nodes,max_depth)\n",
    "    Branches = result[\"branches\"]\n",
    "    Leaves = result[\"leaves\"]\n",
    "#     direct_parent, left_parents, right_parents = get_parent_nodes(num_nodes)\n",
    "    direct_parent = result[\"direct parent\"]\n",
    "    left_parents = result[\"left parents\"]\n",
    "    right_parents = result[\"right parents\"]\n",
    "    \n",
    "    \n",
    "    A = result[\"a\"][:,:]'\n",
    "    grid_x = linspace(0,1,1000)\n",
    "    grid_y = linspace(0,1,1000)\n",
    "    Splits = Dict()\n",
    "\n",
    "    tol = 1e-8\n",
    "    for node in Branches    \n",
    "        if (abs(A[node,2]) <= tol)     # Vertical Split\n",
    "            (curr_x,curr_y) = ((result[\"b\"][node]-A[node,2]*grid_y)/A[node,1], grid_y)\n",
    "        else # Horizontal Split or Hyperplane Split\n",
    "            (curr_x,curr_y) = (grid_x,(result[\"b\"][node]-A[node,1]*grid_x)/A[node,2])\n",
    "        end\n",
    "\n",
    "        if node != 1\n",
    "            for t_l in left_parents[node]\n",
    "                idxs = (A[t_l,1]*curr_x + A[t_l,2]*curr_y .<= result[\"b\"][t_l])\n",
    "                (curr_x,curr_y) = (curr_x[idxs],curr_y[idxs])\n",
    "            end\n",
    "\n",
    "            for t_r in right_parents[node]\n",
    "                idxs = (A[t_r,1]*curr_x + A[t_r,2]*curr_y .>= result[\"b\"][t_r])\n",
    "                (curr_x,curr_y) = (curr_x[idxs],curr_y[idxs])\n",
    "            end\n",
    "        end\n",
    "        idxs = ((curr_y .<= 1) .& (curr_y .>= 0) .& (curr_x .<= 1) .& (curr_x .>= 0))\n",
    "        Splits[node] = (curr_x[idxs],curr_y[idxs])\n",
    "    end\n",
    "    cluster_tree_assignments = get_cluster_assignments(result)\n",
    "    \n",
    "    obj = result[\"obj\"]\n",
    "    mcols = [:red, :blue, :green, :orange, :pink, :yellow];\n",
    "    scatter(Xnor[:,1],Xnor[:,2], markercolor=mcols[cluster_tree_assignments], leg=false, title = \"obj = $obj\")\n",
    "    scatter!(result[\"μ\"][unique(cluster_tree_assignments),1],\n",
    "        result[\"μ\"][unique(cluster_tree_assignments),2], \n",
    "        markercolor=mcols[unique(cluster_tree_assignments)], m=[:star7], markersize = 10)\n",
    "    for i in 1:length(result[\"d\"]) \n",
    "        plot!(Splits[i][1],Splits[i][2]) \n",
    "    end\n",
    "    plot!()\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = [10,10,10,10]#[20,20,20,20]#\n",
    "μ = [[10,10],[10,10],[10,10],[10,10]]\n",
    "μ = [[10,10],[10,0],[5,5],[0,5]]\n",
    "σ = [1/2.9, 1/2.5, 1/1.9, 1/1.9]\n",
    "X = create_synthetic_data(n,μ,σ)\n",
    "Xnor = feature_scaling(X)\n",
    "Y = synthetic_data_cluster_assignments(n);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" />"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcols = [:red, :blue, :green, :orange]\n",
    "scatter(Xnor[:,1],Xnor[:,2], markercolor=mcols[Y], leg=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_p = 0.1\n",
    "max_depth = 3\n",
    "K = 6\n",
    "@time result = ClusterTree(Xnor,c_p,max_depth,K);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster_tree(result,max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 6\n",
    "@time kmeans_clusters = kmeans(Xnor',K)\n",
    "mcols = [:red, :blue, :green, :orange, :pink, :yellow]\n",
    "scatter(Xnor[:,1],Xnor[:,2], markercolor=mcols[assignments(kmeans_clusters)], leg=false)\n",
    "scatter!(kmeans_clusters.centers[1,:],kmeans_clusters.centers[2,:], markercolor=mcols, m=[:star7], markersize = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using GraphViz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split_text (generic function with 1 method)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function split_text(result)\n",
    "    a = result[\"a\"][:,:]'\n",
    "    b = round.(result[\"b\"][:],2)\n",
    "    n, p = size(a)\n",
    "    for i = 1:n\n",
    "        result = string()\n",
    "        for j = 1:p\n",
    "            if a[i,j] != 0\n",
    "                if isempty(result)\n",
    "                    result = string(result,\"$(a[i,j])\",\"x$(j)\")\n",
    "                else\n",
    "                    result = string(result,\" + \",\"$(a[i,j])\",\"x$(j)\")\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        result = string(result, \" < $(b[i])\")\n",
    "        println(result)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0x1 < 0.71\n",
      "1.0x1 < 0.33\n",
      " < 0.0\n",
      "1.0x2 < 0.51\n",
      " < 0.0\n",
      " < 0.0\n",
      " < 0.0\n"
     ]
    }
   ],
   "source": [
    "split_text(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: graphname Pages: 1 -->\n",
       "<svg width=\"134pt\" height=\"188pt\"\n",
       " viewBox=\"0.00 0.00 134.00 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n",
       "<title>graphname</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-184 130,-184 130,4 -4,4\"/>\n",
       "<!-- a -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>a</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"63\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"63\" y=\"-157.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Foo</text>\n",
       "</g>\n",
       "<!-- b -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>b</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"90,-108 36,-108 36,-72 90,-72 90,-108\"/>\n",
       "<text text-anchor=\"middle\" x=\"63\" y=\"-85.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">b</text>\n",
       "</g>\n",
       "<!-- a&#45;&#45;b -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>a&#45;&#45;b</title>\n",
       "<path fill=\"none\" stroke=\"#0000ff\" d=\"M63,-143.8314C63,-133 63,-119.2876 63,-108.4133\"/>\n",
       "</g>\n",
       "<!-- c -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>c</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"27\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">c</text>\n",
       "</g>\n",
       "<!-- b&#45;&#45;c -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>b&#45;&#45;c</title>\n",
       "<path fill=\"none\" stroke=\"#0000ff\" d=\"M53.9157,-71.8314C48.3334,-60.6667 41.2205,-46.441 35.7089,-35.4177\"/>\n",
       "</g>\n",
       "<!-- d -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>d</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"99\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">d</text>\n",
       "</g>\n",
       "<!-- b&#45;&#45;d -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>b&#45;&#45;d</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" stroke-dasharray=\"1,5\" d=\"M72.0843,-71.8314C77.6666,-60.6667 84.7795,-46.441 90.2911,-35.4177\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "GraphViz.Graph(Ptr{Void} @0x00007ff13bdea370, true)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = Graph(\"\"\"\n",
    "graph graphname {\n",
    "     // The label attribute can be used to change the label of a node\n",
    "     a [label=\"Foo\"];\n",
    "     // Here, the node shape is changed.\n",
    "     b [shape=box];\n",
    "     // These edges both have different line properties\n",
    "     a -- b -- c [color=blue];\n",
    "     b -- d [style=dotted];\n",
    " }\n",
    "\"\"\")\n",
    "GraphViz.layout!(g; engine=\"dot\")\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
